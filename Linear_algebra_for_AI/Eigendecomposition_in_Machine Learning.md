

# Eigendecomposition in Machine Learning

ë¨¸ì‹ ëŸ¬ë‹ ë¬¸ì œì—ì„œëŠ” ì£¼ë¡œ Symmetric Positive(semi-)definiteí•œ í–‰ë ¬ì„ ë‹¤ë£¨ê²Œ ëœë‹¤. 

ë‹¤ìŒê³¼ ê°™ì€ Feature-by-data itemì˜ í–‰ë ¬ ğ´ âˆˆ â„^(ğ‘šÃ—ğ‘›)ê°€ ìˆë‹¤ê³  ê°€ì •í•˜ì.

![](./Figure/Eigendecomposition_in_Machine Learning1.JPG)

A^TAëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ëŒ ë°ì´í„° ê°„ì˜ ë‚´ì ìœ¼ë¡œ ì‚¬ëŒ ë°ì´í„° ì‚¬ì´ì˜ ìœ ì‚¬ë„ë¥¼ í‘œí˜„í•˜ê²Œ ëœë‹¤.

![](./Figure/Eigendecomposition_in_Machine Learning2.JPG)

ë§ˆì°¬ê°€ì§€ë¡œ AA^TëŠ” íŠ¹ì§•ìœ¼ë¡œ ë¬¶ì€ ë²¡í„°ë“¤ì˜ ë‚´ì ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ íŠ¹ì§• ê°„ì˜ ìƒê´€ ê´€ê³„ë¥¼ í‘œí˜„í•˜ê²Œ ëœë‹¤. 

ì´ëŸ°ì‹ìœ¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ê³ ìœ³ê°’ ë¶„í•´ë¥¼ ì‚¬ìš©í•˜ëŠ” ì˜ì—­ì€ ì£¼ì„±ë¶„ ë¶„ì„ì—ì„œ ê³µë¶„ì‚° í–‰ë ¬ì„ êµ¬í•  ë•Œ, ìŠ¤íƒ€ì¼ íŠ¸ëœìŠ¤í¼ì—ì„œ ê·¸ëŒ í–‰ë ¬ì„ êµ¬í•  ë•Œ ë“±ì˜ ê²½ìš°ê°€ ìˆë‹¤. 



- ì°¸ê³  ìë£Œ

  [Principal component analysis1](http://www.math.union.edu/~jaureguj/PCA.pdf)
  [Principal component analysis2]( http://pages.cs.wisc.edu/~jerryzhu/cs540/handouts/PCA.pdf)
  [Lecture on gram matrix in style transfer](https://www.youtube.com/watch?v=VC-YFRSp7lM&amp;feature=youtu.be)

  

